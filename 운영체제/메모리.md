# 메모리

### 메모리 계층
***
메모리 계층은 레지스터, 캐시, 메모리, 저장장치로 이루어져 있습니다.
* 레지스터 : CPU안에 있는 작은 메모리, 휘발성, 속도가 가장 빠르며, 기억 용량이 적습니다.
* 캐시 : L1, L2 캐시를 저장합니다. 휘발성이며, 속도가 빠르며, 기억 용량이 적습니다. L3 캐시도 존재합니다.
* 주기억장치 : RAM을 가리킵니다. 휘발성이며, 보통의 속도를 가지며, 보통정도의 용량을 가지고 있습니다.
* 보조기억장치 : HDD, SSD를 일컬으며, 비휘발성, 속도가 낮고, 용량이 큽니다.

램은 하드디스크로 부터 일정량의 데이터를 복사해서 임시 저장하고 이를 필요 시마다 CPU에 빠르게 전달하는 역할을 합니다.

### 캐시 
***
캐시(cache)는 데이터를 미리 복사해 놓는 임시 저장소이자 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리를 뜻합니다. 메모리와 CPU 사이의 속도 차이가 너무 크기 떄문에 중간의 레지스터 계층을 둬서 속도 차이를 해결합니다. 속도 차이를 해결하기 위해 계층과 계층 사이에 있는 계층을 캐시 계층이라고 합니다. 
<br><br>
### 지역성의 원리
***
캐시 계층을 두는 것 말고 캐시를 직접 설정할때의 유의사항으로는 자주 사용하는 데이터를 기반으로 설정해야 합니다. 자주 사용하는 데이터의 근거로 지역성을 고려해야 합니다. 지역성은 시간 지역성(temporal locality), 공간 지역성(spatial locality)으로 나뉩니다.

* 시간 지역성 : 최근에 사용한 데이터에 다시 접근하려는 특성입니다. 
* 공간 지역성 : 최근 접속한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성을 말합니다.

### 캐시히트와 캐시미스
***
* 캐시히트 : 캐시에서 원하는 데이터를 찾은 것을 말합니다.
* 캐시미스 : 원하는 데이터가 없다면 주메모리로 가서 데이터를 찾아오는 것을 말합니다.
* 캐시매핑 : 캐시매핑은 캐시가 히트되기 위해 매핑하는 방법을 말하며, CPU의 레지스터가 주 메모리(RAM) 간에 데이터를 주고 받을 때를 기반으로 설명합니다. 레지스터는 주 메모리에 비해 용량이 적기 때문에 매핑을 어떻게 해주냐가 중요합니다.
> 매핑의 종류<br>
 1. 직접 매핑(directed mapping) : 메모리가 1~100이 있고 캐시가 1~10이 있다면 1:1~10, 2:1~20 ... 이런 식으로 매핑을 하는 것을 말합니다. 처리가 빠르지만 충돌 발생이 잦습니다.
 2. 연관 매핑(associative mapping) : 순서를 일치 시키지 않고 관련 있는 캐시와 메모리를 매핑합니다. 충돌이 적지만 모든 블록을 탐색하여 속도가 느립니다.
 3. 집합 연관 매핑(set associative mapping) : 직접 매핑과 연관 매핑을 합쳐놓은 것을 말합니다. 효율적인 검색이 가능합니다. 

 ### 웹 브라우저의 캐시
 ***
 스프트웨어적인 대표적인 캐시로는 웹 브라우저의 작은 저장소 쿠키, 로컬 스토리지, 세션 스토리지가 있습니다. 이것은 웹 브라우저에 저장하여 통신시 자신을 나타내는 아이덴티티, 중복 요청 방지에 쓰입니다.
 * 쿠키 : 만료기한이 있는 키-값 저장소 입니다. 
 * 로컬 스토리지 : 만료기한이 없는 카-값 저장소 입니다. 10MB 까지 저장할 수 있으며 브라우저를 닫아도 유지되고, 모메인 단위로 저장, 생성합니다.
 * 세션 스토리지 : 만료기한이 없는 카-값 저장소 입니다. 5MB 까지 저장할 수 있으며 탭을 닫을 때 해당 데이터가 삭제됩니다.
 <br><br>
 ### 데이터베이스의 캐싱 계층
 ***
 데이터베이스 시스템을 구축할 때도 메인 데이터베이스 위에 레디스(redis) 데이터베이스 계층을 캐싱 계층으로 둬서 성능을 향상시키기도 합니다.

 ### 메모리 관리
 ***
 * 가상 메모리 : 가상 메모리는 메모리 관리 기법의 하나로 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여 이를 사용하는 사용자들에게 매우 큰 메모리로 보이게 만드는 것을 말합니다. 가상적으로 주어진 주소를 가상 주소(logical address)라고 하며, 실제 메모리상에 있는 주소를 실제 주소(physical address)라고 합니다. 가상 주소는 메모리관리장치(MMU)에 의해 실제 주소로 변환 되며, 이 덕분에 사용자는 실제 주소를 의식할 필요 없이 프로그램을 구축 할 수 있습니다. 가상 메모리는 가상 주소와 실제 주소가 매핑되어 있고 프로세스의 주소 정보가 들어 있는 페이지 테이블로 관리됩니다. 속도 향상을 위해 TLB를 사용합니다.
 > TLB : 메모리와 CPU 사이에 있는 주소 변환을 위한 캐시입니다. 페이지 테이블에 있는 리스트를 보관하며 CPU가 페이지 테이블까지 가지 않도록 해 속도를 향상시킬수 있는 캐시 계층입니다.
### 스와핑과 페이지 폴트
***
 * 스와핑 : 가상 메모리에는 존재하지만 실제 메모리인 RAM에는 현재 없는 데이터나 코드에 접근할 경우 페이지 폴트가 발생합니다. 이때 메모리에서 당장 사용하지 않은 영역을 하드디스크로 옮기고 하드디스크의 일부분을 마치 메모리처럼 불러와 쓰는 것을 스와핑이라고 합니다. 

 * 페이지 폴트 : 프로세스의 주소 공간에는 존재하지만 지금 이 컴퓨터의 RAM에는 없는 데이터에 접근했을 경우에 발생합니다. 

> 과정
1. CPU는 물리 메모리를 확인하여 해당 페이지가 없으면 트랩을 발생해서 운영체제에 알립니다.
2. 운영체제는 CPU의 동작을 잠시 멈춥니다.
3. 운영체제는 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인하고, 없으면 프로세스를 중단하고 현재 물리 메모리에 비어 있는 프레임이 있는지 찾습니다. 물리 메모리에도 없다면 스와핑이 발생됩니다.
4. 비어 있는 프래임에 해당 페이지를 로드하고, 페이지 테이블을 최신화 합니다.
5. 중단되었던 CPU를 다시 시작합니다.

> 페이지 : 가상 메모리를 사용하는 최소 크기 단위

> 프레임 : 실제 메모리를 사용하는 최소 크기 단위

### 스래싱
***
메모리의 페이지 폴트율이 높은 것을 의미하며, 이는 컴퓨터의 심각한 성능 저하를 초래합니다. 메모리에 너무 많은 프로세스가 동시에 올라가게 되면 스와핑이 많이 일어나서 발생합니다. 이를 해결하기 위한 방법으로는 메모리를 늘리거나, HDD -> SSD 교체 방법이 있습니다. 이외에 운영체제에서 이를 해결할 수 있는 방법은 작업 세트와 PFF가 있습니다. 

* 작업 세트 : 프로세스의 과서 사용 이력인 지역성을 통해 결정된 집합을 미리 만들어서 미리 메모리에 로드하는 것입니다.

* PFF : 페이지 폴트 빈도를 조절하는 방법으로 상한선과 하한선을 만드는 방법입니다. 상향선에 도달한다면 프레임을 늘리고 하한선에 도달한다면 프레임을 줄이는 것입니다.

### 메모리 할당
***
메모리에 프로그램을 할당할 때는 시작 메모리 위치, 메모리의 할당 크기를 기반으로 할당하는데 연속 할당과 불연속 할당으로 나뉩니다.
* 연속 할당 : 메모리에 연속적으로 공간을 할당하는 것입니다.
메모리를 미리 나누어 관리하는 고정 분할 방식과 매 시점 프로그램의 크기에 맞게 메모리를 분할 하여 사용하는 가변 분할 방식이 있습니다.

> 고정 분할 방식 : 메모리를 미리 나누어 관리하는 방식이며, 메모리가 미리 나뉘어 있기 때문에 융통성이 없습니다. 또한 내부 단편화가 발생합니다.

> 가변 분할 방식 : 매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나눠 사용합니다. 내부 단편화는 발생하지 않고 외부 단편화는 발생할 수 있습니다. 이는 최소적합, 최적적합, 최악적합이 있습니다.

> 최소적합 : 위쪽이나 아래쪽부터 시작해서 홀을 찾으면 바로 할당됩니다.
> 최적적합 : 프로세스의 크기 이상인 공간 중 가장 작은 홀부터 할당 합니다.
> 최악적합 : 프로세스의 크기와 가장 많이 차이가 나는 홀에 할당 합니다.

> 내부 단편화 : 메모리를 나눈 크기보다 프로그램이 작아서 들어가지 못하는 공간이 많이 발생하는 현상입니다.
> 외부 단편화 : 메모리를 나눈 크기 보다 프로그램이 커서 들어가지 못하는 공간이 많이 발생하는 현상입니다.
> 홀 : 할당할 수 있는 비어 있는 메모리 공간입니다.

* 불연속 할당 : 메모리를 연속적으로 할당하지 않는 불연속 할당은 현대 운영체제가 쓰는 방법으로 불연속 할당인 페이징 기법이 있습니다.

> 페이징 : 동이랗ㄴ 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스를 할당 합니다. 홀의 크기가 균일하지 않은 문제가 없어지지만 주소 변환이 복잡해집니다.

> 세그멘테이션 : 페이지 단위가 아닌 의미 단위인 세그먼트로 나누는 방식입니다. 프로세스는 코드, 데이터, 스택, 힙 등으로 이루어지는데 코드와 데이터 등 이를 기반으로 나눌 수 있으며, 함수 단위로 나눌 수도 있슴을 의미합니다. 공유와 보안 측면에서 좋으며 홀 크기가 균일하지 않은 문제가 발생합니다. 

> 페이지드 세그멘테이션 : 공유나 보안을 의미 단위의 세그먼트로 나누고, 물리적 메모리는 페이지로 나누는 것을 말합니다.

### 페이지 교체 알고리즘
***
메모리는 한정되어 있기 떄문에 스와핑이 많이 일어납니다. 스와핑은 많이 일어나지 않도록 설계되어야 하며 이는 페이지 교체 알고리즘을 기반으로 스와핑이 일어납니다.

* 오프라인 알고리즘 : 먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘이며, 가장 좋은 방법입니다. 하지만 먼 미래에 사용되는 프로세스를 알 수 없습니다. 사용할 수 없는 알고리즘이지만 다른 알고리즘과의 성능 비교에 사용됩니다.

* FIFO(First Input First Out) : 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법을 의미합니다.

* LRU(Least Recentle Used) : 참조가 가장 오래된 페이지를 바꿉니다. 오래된 것을 파악하기 위해 각 페이지마다 계수기, 스택을 두어야합니다. 프로그래밍으로 구현시 두 개의 자료 구조를 사용합니다. 해시 테이블과 이중 연결 리스트를 사용합니다.

* NUR(Not Used Recently) : LRU 에서 발전한 알고리즘입니다. clock 알고리즘이라고 하며 먼저 0과 1을 가진 비트를 줍니다. 1은 최근 참조되었고, 0은 참조되지 않음을 의미합니다. 시계 방향으로 돌면서 0을 찾고 0을 찾은 순간 프로세스를 교체하고 해당 부분을 1로 바꾸는 알고리즘입니다. 

* LFU(Least Frequently Used) : 가장 참조 횟수가 적은 페이지를 교체합니다. 많이 사용되지 않은 것을 교체하는 알고리즘 입니다.
